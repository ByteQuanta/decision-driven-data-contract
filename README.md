# Decision-Driven Data Contract & Monitoring System

A production-grade data contract system that **measures data quality risk**, **makes automated ingestion decisions**, and **enforces feature-level SLAs** â€” without notebooks, dashboards no one checks, or manual intervention.

This project is not about validating data.

It is about **deciding what happens when data quality degrades**.

---

## ğŸš¨ The Real Problem

Most data quality systems stop at:
- schema checks
- null counts
- dashboards

But production systems donâ€™t fail because metrics exist.  
They fail because **no decision is enforced when data breaks**.

> What should the system do when incoming data is *technically valid*  
> but *operationally dangerous*?

This project answers that question end-to-end.

---

## ğŸ§  Design Philosophy

**Checks â‰  Decisions**  
**Metrics â‰  Actions**

This system explicitly separates:

1. **Measurement** â€“ What is the data quality?
2. **Risk Assessment** â€“ How risky is this for downstream systems?
3. **Decision** â€“ Should we allow, warn, or block ingestion?
4. **Action** â€“ What actually happens in the pipeline?
5. **Auditability** â€“ Why did this decision happen?

This separation mirrors how real ML and data platforms operate at scale.

---

## ğŸ—ï¸ High-Level Architecture

```
Incoming CSVs
â”‚
â–¼
Data Contract (YAML)
â”‚
â–¼
Validator â”€â”€â–º Quality Metrics
â”‚
â–¼
Risk Engine â”€â”€â–º Risk Score
â”‚
â–¼
Decision Engine â”€â”€â–º ALLOW / WARN / BLOCK
â”‚
â–¼
Actions + Audit Log

The system does not ask humans to interpret dashboards.  
It **decides and acts automatically**.

---

## ğŸ“¦ Project Structure

```
data_contract/
â”œâ”€â”€ engine/ # Core decision logic
â”‚ â”œâ”€â”€ loader.py # Load latest incoming data
â”‚ â”œâ”€â”€ validator.py # Compute quality metrics
â”‚ â”œâ”€â”€ risk.py # Metrics â†’ risk
â”‚ â”œâ”€â”€ decision.py # Risk â†’ decision
â”‚ â””â”€â”€ actions.py # Enforced outcomes
â”‚
â”œâ”€â”€ dashboard/
â”‚ â”œâ”€â”€ state.py # Derive system state from logs
â”‚ â””â”€â”€ app.py # CLI operational dashboard
â”‚
â”œâ”€â”€ contracts/ # Data contracts (YAML)
â”œâ”€â”€ scripts/ # Entry points & CI guardrails
â”œâ”€â”€ tests/ # Failure simulation tests
â”‚
â”œâ”€â”€ contract_check.yml # Policy as code
â”œâ”€â”€ pyproject.toml
â””â”€â”€ environment.yml

---

## ğŸ“œ Data Contract Example

```yaml
dataset:
  name: user_features

features:
  user_id:
    dtype: int
    allow_null: false
    max_null_rate: 0.0

  user_age:
    dtype: float
    allow_null: true
    max_null_rate: 0.3

  country_code:
    dtype: str
    allow_null: false

  signup_days_ago:
    dtype: int
    min: 0
    max: 3650
```

Contracts define expectations, not behavior.

---

## âš–ï¸ Risk-Based Decisions

Instead of binary pass/fail checks, the system computes operational risk.

| Risk Score | Decision           | Meaning                        |
| ---------- | ------------------ | ------------------------------ |
| `< 0.25`   | ALLOW              | Safe to ingest                 |
| `0.25â€“0.4` | ALLOW_WITH_ALERT   | Monitor closely                |
| `â‰¥ 0.4`    | BLOCK_AND_ROLLBACK | Prevent silent data corruption |

---

## ğŸ§ª Failure Simulation (Not Happy Paths)

The system is explicitly tested against bad data scenarios.

```bash
pytest tests/test_contract_break.py

```

If risky data passes, tests fail.

This ensures enforcement, not observability theater.

---

## ğŸ›¡ï¸ Policy as Code

Organizational guardrails live outside Python:

```yaml
risk:
  block_threshold: 0.4

ci:
  fail_on:
    - block

```

Changing enforcement rules does not require code changes.

---

## ğŸ“Š Operational Dashboard (CLI)
```bash
python -m dashboard.app

```

Shows:

- current system health

- recent decisions

- most frequent issues

The goal is not visualization.
The goal is operational clarity.

---

# ğŸš€ Running the Pipeline
```bash
pip install -e .
python -m scripts.run_pipeline

```

CI enforcement:
```bash
python -m scripts.ci_check

```

---

## ğŸ’¡ Why This Matters

- No notebooks

- No manual inspection

- No â€œweâ€™ll check it laterâ€

Decisions are:

- automated

- enforced

- logged

- auditable

This is how data quality works in real production systems.

---

## ğŸ”š Final Note

This repository is intentionally complete but minimal.

It favors:

decisions over metrics

systems over scripts

enforcement over observability

That is the point.

---
